# -*- coding: utf-8 -*-
"""CIFAR-10_Images_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18o2Vhp4NXCOFoK6JL3DA2datYk7EFguz

Project to classify the CIFAR-10 dataset

Importing the necessary python libraries
"""

import torch
import torchvision
import torchvision.transforms as Transforms
import torchvision.datasets as Datasets
import torch.utils.data as Data
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F
import cv2

"""Firstly we define transforms for data augmentation. We will use HorizontalFlip and Normalize our data."""

transform = Transforms.Compose([
                               Transforms.RandomHorizontalFlip(),
                               Transforms.Resize((224,224)),
                               Transforms.ToTensor(),
                               Transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])

transform1 = Transforms.Compose([
                               Transforms.Resize((224,224)),
                               Transforms.ToTensor(),
                               Transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])

"""Now we get the CIFAR10 train and CIFAR10 test data"""

train_data = Datasets.CIFAR10(root = './data' , train = True , download = True, transform= transform)
test_data  = Datasets.CIFAR10(root = './data' , train = False , download = True , transform= transform1)

"""Now we will load our data using DataLoader. We will keep the batch size 50."""

train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = 100 , shuffle = True)
test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = 100 , shuffle = False)
print(type(train_data))

classes =  ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship',' truck' )

train_iter = iter(train_loader)
images,labels = train_iter.next()
print(images.shape)
print(images[0].shape)
print(labels.shape)

"""Now let us look at the first few images of our dataset.First we need to change the shape to (32,32,3) which is the standard shape to display the image"""

fig,axs = plt.subplots(nrows = 1 , ncols= 10 , figsize = (12,12))

for img,i in zip(images,range(10)):
  np_img = img.numpy()
  np_img = np.transpose(np_img,(1,2,0))
  np_img = np_img*(0.5,0.5,0.5) + (0.5,0.5,0.5) 
  axs[i].imshow(np_img)
  axs[i].axis('off')
  axs[i].set_title(classes[labels[i]])
plt.show()

"""Now let us design our model. I used the ResNet-50 model however any other ResNet model can be derived from class."""

#Resnet Model
class block(nn.Module):
    def __init__(
        self, in_channels, intermediate_channels, identity_downsample=None, stride=1
    ):
        super(block, self).__init__()
        self.expansion = 4
        self.conv1 = nn.Conv2d(
            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False
        )
        self.bn1 = nn.BatchNorm2d(intermediate_channels)
        self.conv2 = nn.Conv2d(
            intermediate_channels,
            intermediate_channels,
            kernel_size=3,
            stride=stride,
            padding=1,
            bias=False
        )
        self.bn2 = nn.BatchNorm2d(intermediate_channels)
        self.conv3 = nn.Conv2d(
            intermediate_channels,
            intermediate_channels * self.expansion,
            kernel_size=1,
            stride=1,
            padding=0,
            bias=False
        )
        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)
        self.relu = nn.ReLU()
        self.identity_downsample = identity_downsample
        self.stride = stride

    def forward(self, x):
        identity = x.clone()

        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.conv3(x)
        x = self.bn3(x)

        if self.identity_downsample is not None:
            identity = self.identity_downsample(identity)

        x += identity
        x = self.relu(x)
        return x


class ResNet(nn.Module):
    def __init__(self, block, layers, image_channels, num_classes):
        super(ResNet, self).__init__()
        self.in_channels = 64
        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # Essentially the entire ResNet architecture are in these 4 lines below
        self.layer1 = self._make_layer(
            block, layers[0], intermediate_channels=64, stride=1
        )
        self.layer2 = self._make_layer(
            block, layers[1], intermediate_channels=128, stride=2
        )
        self.layer3 = self._make_layer(
            block, layers[2], intermediate_channels=256, stride=2
        )
        self.layer4 = self._make_layer(
            block, layers[3], intermediate_channels=512, stride=2
        )

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * 4, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = x.reshape(x.shape[0], -1)
        x = self.fc(x)

        return x

    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):
        identity_downsample = None
        layers = []

        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes
        # we need to adapt the Identity (skip connection) so it will be able to be added
        # to the layer that's ahead
        if stride != 1 or self.in_channels != intermediate_channels * 4:
            identity_downsample = nn.Sequential(
                nn.Conv2d(
                    self.in_channels,
                    intermediate_channels * 4,
                    kernel_size=1,
                    stride=stride,
                    bias=False
                ),
                nn.BatchNorm2d(intermediate_channels * 4),
            )

        layers.append(
            block(self.in_channels, intermediate_channels, identity_downsample, stride)
        )

        # The expansion size is always 4 for ResNet 50,101,152
        self.in_channels = intermediate_channels * 4

        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,
        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,
        # and also same amount of channels.
        for i in range(num_residual_blocks - 1):
            layers.append(block(self.in_channels, intermediate_channels))

        return nn.Sequential(*layers)

def ResNet50(img_channel=3, num_classes=1000):
    return ResNet(block, [3, 4, 6, 1], img_channel, num_classes)

model = ResNet50(img_channel=3, num_classes=10)
y = model(images)
print(y.size())



''' 
A pretrained ResNet-50 model
model = torchvision.models.resnet50(pretrained= True)
y = model(images)
'''

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
model.to(device)

"""We will define our loss function, our optimizer and the number of epochs"""

criteria = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=5e-4)
num_of_epochs = 40

"""We will initialize some lists that will help us plot our graphs"""

train_loss_list = []
train_accuracy_list = []
test_loss_list=[]
test_accuracy_list = []
print(train_loss_list)

"""Now we will define the training loop

"""

for epoch in range(num_of_epochs):

  train_loss = 0
  test_loss = 0
  total_trained = 0
  correct_trained = 0
  train_accuracy = 0
  total_tested = 0
  correct_tested = 0
  test_accuracy = 0 
  i = 1
  model.train()
  for image,label in train_loader:
   
   image = image.to(device)
   label = label.to(device)
   #forward pass
   train_pred = model(image)

   #calculating the loss
   loss = criteria(train_pred,label)

   #backward pass
   loss.backward()

   #changing weights
   optimizer.step()

   #emptying the gradient 
   optimizer.zero_grad()

   #now lets find the train accuracy and the train loss
   train_loss+= loss.item()
   print(f'Batch {i} done')
   _,train_pred = torch.max(train_pred,1)
   total_trained += label.size(0)
   correct_trained += train_pred.eq(label).sum().item()
   i = i+1
   #displaying the loss for each epoch
  train_loss/= len(train_loader)
  train_accuracy = 100.*(correct_trained/total_trained)
  print(f'Epoch: {epoch+1} , Train Loss: {train_loss} , Train Accuracy: {train_accuracy}' ,  )
  
  
  

   #End of training

   #Now the test loop

  with torch.no_grad():  #we dont want to change our gradient when we test our data
     for image,label in (test_loader):
          
       image = image.to(device)
       label = label.to(device)
       test_pred = model(image)

       loss = criteria(test_pred,label)
       
       #now lets find the train accuracy and the Train loss
       
       test_loss+= loss.item()

       #  The shape of test_pred is (50,10) i.e. it has a classification score for each of the 10 categories.
       # The image belongs to the category with the maximum score.
       # We also need to then transform the tensor into a 1D tensor with shape (50) and the data must be the category.

      
       _,test_pred = torch.max(test_pred,1)
       total_tested += label.size(0)
       correct_tested += test_pred.eq(label).sum().item()
       

     # Displaying the loss for each epoch
     test_loss/= len(test_loader)
     test_accuracy = 100.*(correct_tested/total_tested)
     print(f'Epoch: {epoch+1} , Test Loss: {test_loss} , Test Accuracy: {test_accuracy}' ,  )
    
    #updating our lists

     train_loss_list.append(train_loss)
     test_loss_list.append(test_loss)
     train_accuracy_list.append(train_accuracy)
     test_accuracy_list.append(test_accuracy)

"""Now, we will plot the loss graph and the accuracy graph"""

#accuracy graph
plt.plot(train_accuracy_list, label ='Training Accuracy')
plt.plot(test_accuracy_list, label = 'Validation Accuracy')
plt.legend()

#loss graph
plt.plot(train_loss_list, label ='Training Loss')
plt.plot(test_loss_list, label = 'Validation loss')
plt.legend()

#previous accuracy:

#Custom Model

class Net(nn.Module):

  def __init__(self):
    super(Net,self).__init__()
    self.conv1 = nn.Conv2d(in_channels = 3 , kernel_size=(3,3), stride = 1 , out_channels= 6 )
    self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = (3,3), stride = 1)
    self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 64, kernel_size = (5,5), stride = 1)  
    self.pool = nn.MaxPool2d(kernel_size = (2,2), stride = 2, ceil_mode= True)
    self.fc1 = nn.Linear(in_features=64*54*54,out_features = 120)
    self.fc2 = nn.Linear(in_features = 120,out_features = 84)
    self.fc3 = nn.Linear(in_features=84 , out_features= 10)
    self.do = nn.Dropout(0.3)

  def forward(self,x):
   x = self.pool(F.relu(self.conv1(x)))
   x = (F.relu(self.conv2(x)))
   x = self.pool(F.relu(self.conv3(x)))  
   x = x.view(-1,64*54*54)
   x = F.relu(self.fc1(x))
   x = self.do(x)
   x = F.relu(self.fc2(x))
   x = self.do(x)
   x = self.fc3(x)

   return (x)

model = Net()
y = model(images)
print(y)
